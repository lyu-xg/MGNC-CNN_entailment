# MGNC-CNN_entailment

We document and report experiments training convolutional Neural networks (CNN) on the Stanford Natural Language Inference (SNLI) corpus. We show that by adapting Multi-Group Norm Constraint CNN (MGNC-CNN) model, hence simultaneously exploiting several pre-trained word embeddings, we achieve higher accuracy than using any of the word embeddings alone or combined using multi-channel model, which, on the contrary, typically yield better results in image processing. Although we did not achieve the accuracy showed in other papers of similar methods, we shall then discuss the logic behind this difference, and also describe a simple but highly accurate baseline model; this baseline model also exploits multiple word embeddings simultaneously. In this project report, we will start with discussing the literature that initiated and shaped my project followed by experiments we conducted along with results and implications.
